# TIDYR
## transform from wide to long format
df %>% gather(key, value, x:y, convert = T) # convert keeps values as integers is needed
df %>% gather(key, value, -z)

## transform from long to wide format
df %>% spread(colnames, value)

## 
df %>% separate(old_col, new_colnames, sep)
# dat %>% separate(key, c("year","variable_name"), sep = "_")
# dat %>% separate(key, c("year","variable_name_1","variable_name_2"), sep = "_", fill = "right")
# dat %>% separate(key, c("year","variable_name"), sep = "_", extra = "merge")

df %>% unite(new_col, c("old_col_1","old_col_2"))

# GGPLOT2
df %>%
    ggplot(., aes(x,y)) +
    geom_point() +
    scale_x_continuous(trans = "log2") +
    scale_y_continuous(trans = "log2")

# DPLYR
bind_rows(df1, df2)
bind_cols(df1, df2)
union(df1, df2)
intersect(df1, df2)
setdiff(df1, df2)
setequal(df1, df2) # see whether dataframes are equal, regardless of row order

# WEB SCRAPING: RVEST
library(rvest)
## example 1
url1 <- "https://en.wikipedia.org/wiki/Demographics_of_China"
h1 <- read_html(url1)
class(h1) # "xml_document" "xml_node" 
# view page source and look for <table class="wikitable">
html_nodes()
html_node()
tab1 <- h1 %>% html_nodes("table")
tab1 <- tab1[[3]] %>% html_table() # data.frame

## example 2
url <- "https://en.wikipedia.org/wiki/Murder_in_the_United_States_by_state"
h <- read_html(url)
tab <- h %>% html_nodes("table")
tab <- tab[[2]]
tab <- tab %>% html_table()
tab <- tab %>% setNames(c("state", "population", "total", "murders", "gun_murders", "gun_ownership", "total_rate", "murder_rate", "gun_murder_rate"))
head(tab)

## example 3 (more generic web scraping)
h <- read_html("http://www.foodnetwork.com/recipes/alton-brown/guacamole-recipe-1940609")
recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
guacamole <- list(recipe, prep_time, ingredients)
guacamole

get_recipe <- function(url){
    h <- read_html(url)
    recipe <- h %>% html_node(".o-AssetTitle__a-HeadlineText") %>% html_text()
    prep_time <- h %>% html_node(".m-RecipeInfo__a-Description--Total") %>% html_text()
    ingredients <- h %>% html_nodes(".o-Ingredients__a-Ingredient") %>% html_text()
    return(list(recipe = recipe, prep_time = prep_time, ingredients = ingredients))
} 

get_recipe("http://www.foodnetwork.com/recipes/food-network-kitchen/pancakes-recipe-1913844")

## other functions from {rvest}

html_form()
set_values()
submit_form() # these three functions permit to query a webpage from R

## example 4
url <- "https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm"
h <- read_html(url)
nodes <- html_nodes(h, "table")
html_text(nodes[[8]])
html_table(nodes[[8]])